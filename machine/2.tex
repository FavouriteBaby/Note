\documentclass{article}
\usepackage{ctex}
\usepackage{graphics}
\usepackage{geometry}
\usepackage{listings}
\usepackage[colorlinks,linkcolor=red,anchorcolor=blue,citecolor=green]{hyperref}
\setlength{\parindent}{2pt}
% bmeps -c test.png test.eps
\geometry{left=2.0cm,right=2.0cm,top=2.0cm,bottom=2.0cm}
\definecolor{cGray}{RGB}{230,230,250}
\newcommand{\code}[1]{\colorbox[RGB]{255,182,193}{\textcolor[RGB]{220,20,60}{#1}}}
\title{单变量线性回归}
\author{pwlin1992@gmail.com}
\begin{document}
\maketitle
\tableofcontents
\begin{large}
  \section{模型表示}
  \paragraph{例子}\mbox{} \\
  \indent 根据房子的大小，给出房子的价格。

  这是一个监督学习，因为对于每个训练数据，我们都知道其房子大小所对应的价格。更具体一点，这是回归问题，因为最终的结果是一个连续变量。

  \begin{enumerate}
  \item m

    训练集中实例的数量
  \item x

    特征/输入变量
  \item y

    目标变量/输出变量
  \item (x, y)

    训练集中的实例
  \item $(x^{(i)}, y^{(i)})$

    第i个观察实例
  \item h

    学习算法的解决方案或函数，也称为假设
  \end{enumerate}

  \paragraph{监督学习算法的工作方式}\mbox{} \\
  \begin{figure}[h]
    \centering
    \includegraphics{0.PNG}
    \caption{监督学习的工作方式}
  \end{figure}
  \indent 学习算法学完训练数据后，输出h，h表示一个函数，输入房子的大小x，输出房子的价格y。即：h是x到y的函数映射。h的表达方式有可能是$h_\theta(x)=\theta_0+\theta_1x$。因为只含有一个特征/输入变量，因此这样的问题叫做单变量线性回归问题。

  \section{代价函数}
  代价函数的作用是为我们的模型选择合适的参数$\theta_0$和$\theta_1$。参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距就是\textbf{建模误差}。最终目标是选择出可以让\textbf{建模误差的平方和}能够最小的模型参数。即：使代价函数$J(\theta_0, \theta_1)=\frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2$最小。

  \begin{figure}[h]
    \centering
    \includegraphics{1.PNG}
    \caption{等高线图}
  \end{figure}
  可以看出，在三维空间中，存在一个使$J(\theta_0, \theta_1)$最小的点。代价函数也称为平方误差函数，之所以选择平方误差函数，是因为对于大部分问题，特别是回归问题，都是一个合理的选择。

  \section{代价函数的直观理解}
  先来一个简单的情况，对于代价函数，如果其$\theta_0$为0的话，则$h_\theta(x)=\theta_1x$，此时，$J(\theta_1)=\frac{1}{2m}\sum_{i=1}^{m}(h_{\theta_1}(x^{(i)})-y^{(i)})^2$。记住，$h_\theta(x)$是预测房子价格的那个函数。

  首先，取$\theta_1=1$，则$h_\theta(x)=x$，可以取其中三个点：$(1,1)$，$(2,2)$，$(3,3)$，计算代价函数$J(\theta_1)=\frac{1}{2m}[(1-1)^2+(2-2)^2+(3-3)^2]=0$。这是其中一种情况，还可以取$\theta_1$为其他值的情况。最后，以$\theta_1$为横轴，$J(\theta_1)$为纵轴，可以画出一条$J(\theta_1)$与$\theta_1$之间的关系的线。如图所示：
  \begin{figure}[h]
    \centering
    \includegraphics[scale=0.7]{2.PNG}
  \end{figure}

  对应于不同的函数$h(x)$，都会有一个不同的$J(\theta_1)$，并且在$\theta_1$为1时，取得最小值。

  当然，我们最终所需要的是一种有效的算法，能够自动找出使代价函数$J$取最小值的参数$\theta_0$和$\theta_1$。我们的目的不是编写程序把这些点画出来，然后人工判断什么时候最小，因为后面有可能会遇到更复杂、更高维度、更多参数的情况，这些情况很难画出图形来，无法可视化，所以我们真正需要的是编写程序来找出这些最小化代价函数的$\theta_0$和$\theta_1$。
\end{large}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
